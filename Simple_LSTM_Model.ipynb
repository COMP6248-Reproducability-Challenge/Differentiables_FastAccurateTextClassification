{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhlVjbx-Zh9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Execute this code block to install dependencies when running on colab\n",
        "try:\n",
        "    import torch\n",
        "except:\n",
        "    from os.path import exists\n",
        "    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n",
        "    ! pip install --upgrade git+https://github.com/sovrasov/flops-counter.pytorch.git\n",
        "\n",
        "try:\n",
        "    import torchtext\n",
        "except:\n",
        "    !pip install torchtext\n",
        "    \n",
        "try:\n",
        "    import spacy\n",
        "except:\n",
        "    !pip install spacy\n",
        "    \n",
        "try:\n",
        "    spacy.load('en')\n",
        "except:\n",
        "    !python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wovb26Yr1Uk",
        "colab_type": "text"
      },
      "source": [
        "# Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-T4VsjoZlYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.distributions import Categorical\n",
        "from torchtext import datasets\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import os.path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9C3tPlZZrBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field(tokenize='spacy', lower=True, include_lengths=True)\n",
        "LABEL = data.LabelField(dtype=torch.float)\n",
        "_train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anWyjQAwZrvi",
        "colab_type": "code",
        "outputId": "3cd1d7e7-6d16-4336-fada-6ca57c0d7b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "train_data, valid_data = _train_data.split(0.8)\n",
        "\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjjynYwDcgBj",
        "colab_type": "code",
        "outputId": "dfbbac24-c004-46be-9ae9-e6110f921fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "TEXT.build_vocab(train_data, max_size=100000, vectors=\"glove.6B.100d\")\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 91454\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoSIIOpmlhsR",
        "colab_type": "code",
        "outputId": "76a3859a-b043-4e3b-d8aa-d6eabc9a2564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device = 'cpu'\n",
        "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ-krEODTunN",
        "colab_type": "text"
      },
      "source": [
        "# Model and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQnA9EazmYT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 50\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device,\n",
        "    shuffle = False,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    sort_within_batch=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iis6f53adVHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reward_function(prob, true_label):\n",
        "    \"\"\"\n",
        "    Returns 1 if correct prediction, -1 otherwise\n",
        "    \"\"\"\n",
        "    # print(\"true_label\", \"prob\", true_label, prob)\n",
        "    if prob>0.5 and true_label>0.5:\n",
        "        return torch.tensor(1.0, requires_grad=True)\n",
        "    if prob<0.5 and true_label<0.5:\n",
        "        return torch.tensor(1.0, requires_grad=True)\n",
        "    return torch.tensor(-1.0, requires_grad=True)\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, gamma=0.99, train_mode=True):\n",
        "        super().__init__()\n",
        "        \n",
        "        # store dimensions and constants\n",
        "        self.input_dim = input_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.train_mode = True\n",
        "        \n",
        "        # create layers\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.lstm_cell = nn.LSTMCell(input_size = embedding_dim, hidden_size = hidden_dim, bias = True)\n",
        "        self.output_linear = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        # Initialize lstm_cell states\n",
        "        self.initialize_lstm_cell_states()\n",
        "        \n",
        "        # Initalize episode number and time number\n",
        "        self.initialize_for_new_batch()\n",
        "        self.initialize_time_number()\n",
        "        \n",
        "        # Overall reward and loss history\n",
        "        self.reward_history = []\n",
        "        self.loss_history = []\n",
        "        self.training_accuracies = []\n",
        "        self.validation_accuracies = []\n",
        "        \n",
        "        # torch.tensor((0.0), requires_grad=True) \n",
        "    \n",
        "    def initialize_lstm_cell_states(self):\n",
        "        self.c = torch.zeros(1, self.hidden_dim, requires_grad=True)\n",
        "        self.h = torch.zeros(1, self.hidden_dim, requires_grad=True)\n",
        "        \n",
        "    def initialize_episode_number(self):\n",
        "        self.ep = 0\n",
        "    \n",
        "    def initialize_time_number(self):\n",
        "        self.t = 0\n",
        "    \n",
        "    def clear_batch_lists(self):\n",
        "        del self.label_targets[:]\n",
        "        del self.label_predictions[:]\n",
        "        self.initialize_episode_number()\n",
        "        self.training_accuracy = 0.0\n",
        "    \n",
        "    def initialize_for_new_batch(self):\n",
        "        \"\"\"\n",
        "        Cleans history of log probabilities, rewards, targets etc for the last\n",
        "        batch\n",
        "        \"\"\"\n",
        "        self.initialize_episode_number()\n",
        "        \n",
        "        # Episode policy and reward history \n",
        "\n",
        "        # Predictions and targets history (for cross entropy loss calculation)\n",
        "        self.label_predictions = [] # 1 probability for each episode\n",
        "        self.label_targets = []# 1 label for each episode\n",
        "        self.training_accuracy = 0.0\n",
        "\n",
        "        \n",
        "    def classify(self):\n",
        "        out = self.output_linear(self.c[0])\n",
        "        self.label_predictions.append(out)\n",
        "        # return torch.sigmoid(out)\n",
        "    \n",
        "    def save_training_accuracy(self):\n",
        "        correct = 0\n",
        "        for (t, p) in zip(self.label_targets, self.label_predictions):\n",
        "            if reward_function(p, t) > 0:\n",
        "                correct += 1\n",
        "        self.training_accuracy = correct/len(self.label_targets)\n",
        "        self.training_accuracies.append(self.training_accuracy)\n",
        "      \n",
        "    \n",
        "    def forward(self, pack):\n",
        "        texts, lengths, labels = pack\n",
        "        embeddeds = self.embedding(texts)\n",
        "        # embeddeds = nn.utils.rnn.pack_padded_sequence(embeddeds, lengths)\n",
        "        self.initialize_for_new_batch()\n",
        "\n",
        "        for episode_number in range(embeddeds.shape[1]):\n",
        "            \n",
        "            # load episode data\n",
        "            self.ep = episode_number\n",
        "            embedded = embeddeds[:, self.ep, :]\n",
        "      \n",
        "            #print(texts.shape, embeddeds.shape, embedded.shape)\n",
        "            #print(label)\n",
        "            \n",
        "            # initialize counters and index\n",
        "            tokens_read = 0\n",
        "            word_index = 0\n",
        "            words_len = embedded.shape[0]\n",
        "            self.initialize_lstm_cell_states()\n",
        "            self.initialize_time_number()\n",
        "            \n",
        "            if self.train_mode:\n",
        "                label = labels[self.ep].reshape(1)\n",
        "                self.label_targets.append(label)\n",
        "            \n",
        "                # start iterating through sequence, while skipping some words\n",
        "                while word_index<words_len:\n",
        "                    self.t += 1\n",
        "                    embedded_word = embedded[word_index]\n",
        "\n",
        "                     # generate next lstm cell state\n",
        "                    self.h, self.c = self.lstm_cell(torch.reshape(embedded_word, (1, -1)), (self.h, self.c))\n",
        "                    word_index += 1\n",
        "                    # print('word_index', word_index, 'tokens_read', tokens_read, 'jumps_made', jumps_made)\n",
        "              \n",
        "                    # if time to jump words\n",
        "                self.classify()\n",
        "        if self.train_mode:\n",
        "            self.save_training_accuracy()\n",
        "        return self.label_predictions \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyrocBqSF98w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "seed = 7\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(seed)\n",
        "\n",
        "bce = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "simple_model = SimpleModel(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM).to(device)\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "simple_model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "if os.path.exists('simple_model.weights'):\n",
        "    simple_model.load_state_dict(torch.load('simple_model.weights'))\n",
        "\n",
        "# define the optimiser\n",
        "optimizer = optim.Adam(simple_model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9A3CLqzugLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_policy():\n",
        "   \n",
        "    #print(len(policy_model.rewards), len(policy_model.label_predictions), len(policy_model.label_targets))\n",
        "    #print(len(policy_model.saved_log_probs), len(policy_model.reward_baselines))\n",
        "    \n",
        "    J1 = bce(\n",
        "        torch.cat(simple_model.label_predictions),\n",
        "        torch.cat(simple_model.label_targets)\n",
        "    )\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    # print('policy_loss', policy_loss)\n",
        "    J1.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    \n",
        "    simple_model.clear_batch_lists()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-mGeEeZZgRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model():\n",
        "    simple_model.train_mode = True\n",
        "    correct = 0\n",
        "    total=0\n",
        "    for _data in test_iterator:\n",
        "        # get the inputs\n",
        "        texts, text_lengths, labels = _data.text[0], _data.text[1], _data.label\n",
        "        # print(\"Input review texts, text_lengths, labels\", texts.shape, text_lengths.shape, labels.shape)\n",
        "        predictions = simple_model((texts.to(device), text_lengths.to(device), labels.to(device)))\n",
        "        for (prediction, label) in zip(predictions, labels):\n",
        "            if reward_function(label, prediction) > 0:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "        if total%1000 == 0:\n",
        "            print(total)\n",
        "        if total%5000 == 0:\n",
        "            break\n",
        "    print(\"Test accuracy :\", correct/total)\n",
        "    simple_model.train_mode = True\n",
        "    return correct/total\n",
        "\n",
        "def validate_model():\n",
        "    simple_model.train_mode = True\n",
        "    correct = 0\n",
        "    total=0\n",
        "    for _data in valid_iterator:\n",
        "        # get the inputs\n",
        "        texts, text_lengths, labels = _data.text[0], _data.text[1], _data.label\n",
        "        # print(\"Input review texts, text_lengths, labels\", texts.shape, text_lengths.shape, labels.shape)\n",
        "        predictions = simple_model((texts.to(device), text_lengths.to(device), labels.to(device)))\n",
        "        for (prediction, label) in zip(predictions, labels):\n",
        "            if reward_function(label, prediction) > 0:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "        if total%1000 == 0:\n",
        "            break\n",
        "    print(\"Validation accuracy :\", correct/total)\n",
        "    simple_model.validation_accuracies.append(correct/total)\n",
        "    simple_model.train_mode = True\n",
        "    return correct/total\n",
        "\n",
        "# test_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grN0kN4pL1BX",
        "colab_type": "code",
        "outputId": "b9bbe20a-b920-493e-933c-9d63399bfbb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3344
        }
      },
      "source": [
        "# the epoch loop\n",
        "\n",
        "with torch.enable_grad():\n",
        "    validate_model()\n",
        "    for epoch in range(5):\n",
        "        running_reward = 10\n",
        "        t = 0\n",
        "        for _data in train_iterator:\n",
        "            # get the inputs\n",
        "            texts, text_lengths, labels = _data.text[0], _data.text[1], _data.label\n",
        "            # print(\"Input review texts, text_lengths, labels\", texts.shape, text_lengths.shape, labels.shape)\n",
        "            prediction = simple_model((texts.to(device), text_lengths.to(device), labels.to(device)))\n",
        "            # print(\"Prediction\", prediction.item())        \n",
        "            # raise ValueError('Not done')\n",
        "            t += 1\n",
        "            if t%2 == 0:\n",
        "                print(\"batch no. %d, training accuracy %4.2f\" % (t, simple_model.training_accuracy))\n",
        "            if t%10 == 0:\n",
        "                validate_model()\n",
        "            if t%1000 == 0:\n",
        "                break\n",
        "            update_policy()\n",
        "        print(\"Epoch %d\" % (epoch))\n",
        "    print('**** Finished Training ****')\n",
        "# test_model()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy : 0.449\n",
            "batch no. 2, training accuracy 0.54\n",
            "batch no. 4, training accuracy 0.36\n",
            "batch no. 6, training accuracy 0.40\n",
            "batch no. 8, training accuracy 0.36\n",
            "batch no. 10, training accuracy 0.46\n",
            "Validation accuracy : 0.45\n",
            "batch no. 12, training accuracy 0.58\n",
            "batch no. 14, training accuracy 0.48\n",
            "batch no. 16, training accuracy 0.44\n",
            "batch no. 18, training accuracy 0.56\n",
            "batch no. 20, training accuracy 0.50\n",
            "Validation accuracy : 0.449\n",
            "batch no. 22, training accuracy 0.56\n",
            "batch no. 24, training accuracy 0.58\n",
            "batch no. 26, training accuracy 0.54\n",
            "batch no. 28, training accuracy 0.50\n",
            "batch no. 30, training accuracy 0.48\n",
            "Validation accuracy : 0.449\n",
            "batch no. 32, training accuracy 0.74\n",
            "batch no. 34, training accuracy 0.50\n",
            "batch no. 36, training accuracy 0.38\n",
            "batch no. 38, training accuracy 0.44\n",
            "batch no. 40, training accuracy 0.52\n",
            "Validation accuracy : 0.449\n",
            "batch no. 42, training accuracy 0.50\n",
            "batch no. 44, training accuracy 0.54\n",
            "batch no. 46, training accuracy 0.56\n",
            "batch no. 48, training accuracy 0.50\n",
            "batch no. 50, training accuracy 0.42\n",
            "Validation accuracy : 0.453\n",
            "batch no. 52, training accuracy 0.46\n",
            "batch no. 54, training accuracy 0.60\n",
            "batch no. 56, training accuracy 0.48\n",
            "batch no. 58, training accuracy 0.58\n",
            "batch no. 60, training accuracy 0.64\n",
            "Validation accuracy : 0.455\n",
            "batch no. 62, training accuracy 0.44\n",
            "batch no. 64, training accuracy 0.70\n",
            "batch no. 66, training accuracy 0.64\n",
            "batch no. 68, training accuracy 0.62\n",
            "batch no. 70, training accuracy 0.62\n",
            "Validation accuracy : 0.601\n",
            "batch no. 72, training accuracy 0.76\n",
            "batch no. 74, training accuracy 0.50\n",
            "batch no. 76, training accuracy 0.48\n",
            "batch no. 78, training accuracy 0.62\n",
            "batch no. 80, training accuracy 0.74\n",
            "Validation accuracy : 0.732\n",
            "batch no. 82, training accuracy 0.38\n",
            "batch no. 84, training accuracy 0.58\n",
            "batch no. 86, training accuracy 0.56\n",
            "batch no. 88, training accuracy 0.62\n",
            "batch no. 90, training accuracy 0.48\n",
            "Validation accuracy : 0.519\n",
            "batch no. 92, training accuracy 0.68\n",
            "batch no. 94, training accuracy 0.58\n",
            "batch no. 96, training accuracy 0.56\n",
            "batch no. 98, training accuracy 0.42\n",
            "batch no. 100, training accuracy 0.50\n",
            "Validation accuracy : 0.543\n",
            "batch no. 102, training accuracy 0.44\n",
            "batch no. 104, training accuracy 0.54\n",
            "batch no. 106, training accuracy 0.40\n",
            "batch no. 108, training accuracy 0.44\n",
            "batch no. 110, training accuracy 0.38\n",
            "Validation accuracy : 0.462\n",
            "batch no. 112, training accuracy 0.56\n",
            "batch no. 114, training accuracy 0.48\n",
            "batch no. 116, training accuracy 0.34\n",
            "batch no. 118, training accuracy 0.52\n",
            "batch no. 120, training accuracy 0.50\n",
            "Validation accuracy : 0.484\n",
            "batch no. 122, training accuracy 0.52\n",
            "batch no. 124, training accuracy 0.58\n",
            "batch no. 126, training accuracy 0.56\n",
            "batch no. 128, training accuracy 0.48\n",
            "batch no. 130, training accuracy 0.66\n",
            "Validation accuracy : 0.604\n",
            "batch no. 132, training accuracy 0.70\n",
            "batch no. 134, training accuracy 0.54\n",
            "batch no. 136, training accuracy 0.70\n",
            "batch no. 138, training accuracy 0.68\n",
            "batch no. 140, training accuracy 0.70\n",
            "Validation accuracy : 0.565\n",
            "batch no. 142, training accuracy 0.78\n",
            "batch no. 144, training accuracy 0.66\n",
            "batch no. 146, training accuracy 0.72\n",
            "batch no. 148, training accuracy 0.76\n",
            "batch no. 150, training accuracy 0.92\n",
            "Validation accuracy : 0.739\n",
            "batch no. 152, training accuracy 0.88\n",
            "batch no. 154, training accuracy 0.84\n",
            "batch no. 156, training accuracy 0.78\n",
            "batch no. 158, training accuracy 0.76\n",
            "batch no. 160, training accuracy 0.80\n",
            "Validation accuracy : 0.836\n",
            "batch no. 162, training accuracy 0.76\n",
            "batch no. 164, training accuracy 0.76\n",
            "batch no. 166, training accuracy 0.82\n",
            "batch no. 168, training accuracy 0.82\n",
            "batch no. 170, training accuracy 0.88\n",
            "Validation accuracy : 0.841\n",
            "batch no. 172, training accuracy 0.82\n",
            "batch no. 174, training accuracy 0.82\n",
            "batch no. 176, training accuracy 0.86\n",
            "batch no. 178, training accuracy 0.86\n",
            "batch no. 180, training accuracy 0.84\n",
            "Validation accuracy : 0.826\n",
            "batch no. 182, training accuracy 0.96\n",
            "batch no. 184, training accuracy 0.88\n",
            "batch no. 186, training accuracy 0.84\n",
            "batch no. 188, training accuracy 0.68\n",
            "batch no. 190, training accuracy 0.86\n",
            "Validation accuracy : 0.803\n",
            "batch no. 192, training accuracy 0.72\n",
            "batch no. 194, training accuracy 0.84\n",
            "batch no. 196, training accuracy 0.78\n",
            "batch no. 198, training accuracy 0.88\n",
            "batch no. 200, training accuracy 0.54\n",
            "Validation accuracy : 0.784\n",
            "batch no. 202, training accuracy 0.78\n",
            "batch no. 204, training accuracy 0.82\n",
            "batch no. 206, training accuracy 0.90\n",
            "batch no. 208, training accuracy 0.84\n",
            "batch no. 210, training accuracy 0.84\n",
            "Validation accuracy : 0.846\n",
            "batch no. 212, training accuracy 0.84\n",
            "batch no. 214, training accuracy 0.82\n",
            "batch no. 216, training accuracy 0.82\n",
            "batch no. 218, training accuracy 0.84\n",
            "batch no. 220, training accuracy 0.94\n",
            "Validation accuracy : 0.826\n",
            "batch no. 222, training accuracy 0.88\n",
            "batch no. 224, training accuracy 0.82\n",
            "batch no. 226, training accuracy 0.86\n",
            "batch no. 228, training accuracy 0.78\n",
            "batch no. 230, training accuracy 0.84\n",
            "Validation accuracy : 0.793\n",
            "batch no. 232, training accuracy 0.88\n",
            "batch no. 234, training accuracy 0.84\n",
            "batch no. 236, training accuracy 0.84\n",
            "batch no. 238, training accuracy 0.86\n",
            "batch no. 240, training accuracy 0.82\n",
            "Validation accuracy : 0.851\n",
            "batch no. 242, training accuracy 0.84\n",
            "batch no. 244, training accuracy 0.86\n",
            "batch no. 246, training accuracy 0.78\n",
            "batch no. 248, training accuracy 0.82\n",
            "batch no. 250, training accuracy 0.86\n",
            "Validation accuracy : 0.837\n",
            "batch no. 252, training accuracy 0.80\n",
            "batch no. 254, training accuracy 0.88\n",
            "batch no. 256, training accuracy 0.80\n",
            "batch no. 258, training accuracy 0.90\n",
            "batch no. 260, training accuracy 0.88\n",
            "Validation accuracy : 0.861\n",
            "batch no. 262, training accuracy 0.84\n",
            "batch no. 264, training accuracy 0.84\n",
            "batch no. 266, training accuracy 0.86\n",
            "batch no. 268, training accuracy 0.90\n",
            "batch no. 270, training accuracy 0.88\n",
            "Validation accuracy : 0.841\n",
            "batch no. 272, training accuracy 0.92\n",
            "batch no. 274, training accuracy 0.88\n",
            "batch no. 276, training accuracy 0.86\n",
            "batch no. 278, training accuracy 0.76\n",
            "batch no. 280, training accuracy 0.86\n",
            "Validation accuracy : 0.842\n",
            "batch no. 282, training accuracy 0.90\n",
            "batch no. 284, training accuracy 0.90\n",
            "batch no. 286, training accuracy 0.92\n",
            "batch no. 288, training accuracy 0.86\n",
            "batch no. 290, training accuracy 0.86\n",
            "Validation accuracy : 0.857\n",
            "batch no. 292, training accuracy 0.86\n",
            "batch no. 294, training accuracy 0.90\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-28de1bbb3b79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# print(\"Input review texts, text_lengths, labels\", texts.shape, text_lengths.shape, labels.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;31m# print(\"Prediction\", prediction.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# raise ValueError('Not done')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-b963e4cf8b3e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pack)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                      \u001b[0;31m# generate next lstm cell state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                     \u001b[0mword_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0;31m# print('word_index', word_index, 'tokens_read', tokens_read, 'jumps_made', jumps_made)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    539\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mremove_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsVIR2ucBUI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(simple_model.state_dict(), 'simple_model.weights')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOKFyGxf3dkQ",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reYP11IuGriR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "080bdbec-f639-4a36-ac10-474ac6768124"
      },
      "source": [
        "import timeit\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.train_mode = False\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    # tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = torch.LongTensor(indexed).to('cpu')\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    model((tensor, torch.tensor([tensor.shape[0]]), None))\n",
        "    res = torch.sigmoid(model.label_predictions[0])\n",
        "    model.train_mode = False\n",
        "    return res\n",
        "\n",
        "times = []\n",
        "lengths=[]\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size=1,\n",
        "    device=device,\n",
        "    shuffle = True,\n",
        "    # sort_key=lambda x: len(x.text),\n",
        "    sort_within_batch=False)\n",
        "\n",
        "i = 0\n",
        "for _data in test_iterator:\n",
        "    if i%100 == 0:\n",
        "        # get the inputs\n",
        "        texts, text_lengths, labels = _data.text[0], _data.text[1], _data.label\n",
        "        # print(texts.shape, text_lengths.shape, labels.shape)\n",
        "        start_time = timeit.default_timer()\n",
        "        predictions = simple_model((texts.to(device), text_lengths.to(device), labels.to(device)))\n",
        "        elapsed = timeit.default_timer() - start_time\n",
        "        lengths.append(texts.shape[0])\n",
        "        times.append(elapsed)\n",
        "        # print(\"Input review texts, text_lengths, labels\", texts.shape, text_lengths.shape, labels.shape)\n",
        "    if i>20000:\n",
        "        break\n",
        "    i += 1\n",
        "\n",
        "import pickle\n",
        "\n",
        "pickle_out = open(\"test_times_2.pickle\",\"wb\")\n",
        "pickle.dump((lengths, times), pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "\n",
        "plt.scatter(lengths, times)\n",
        "plt.xlabel('Lengths of review')\n",
        "plt.ylabel('Time taken for prediction')\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xu0XHV99/H3JyeHcAJCQFKXHkgT\nkGJREPAIVHxs1UpAqokaBcVH7GKVWsULralh1cpFuwjSije88HjHCyBiGh5UtIZWi4o5MYEQJBoB\nJUefGoEgmAC5fJ8/9h4ymczM3jOz91zO+bzWmpWZPXv2fGfDme/s3+X7U0RgZmbWzLReB2BmZv3P\nycLMzDI5WZiZWSYnCzMzy+RkYWZmmZwszMwsk5OFmZllcrIwM7NMThZmZpZpeq8DKMpBBx0Uc+fO\n7XUYZmYDZdWqVb+LiNlZ+02aZDF37lzGx8d7HYaZ2UCR9Ms8+7kZyszMMjlZmJlZJicLMzPL5GRh\nZmaZnCzMzCyTk4WZmWVysjAzs0xOFmZmlsnJwszMMjlZmJlZJicLMzPL5GRhZmaZSk0Wkk6RtF7S\nBklL6jz/Akk/kbRd0qKa586S9PP0dlaZcZqZWXOlJQtJQ8AVwKnAkcBrJR1Zs9uvgDcCX6557YHA\nBcAJwPHABZIOKCtWMzNrrswri+OBDRFxd0Q8DlwNLKjeISLujYjbgZ01r50PfCciHoiIB4HvAKeU\nGKuZmTVRZrIYBe6rerwx3Vb2a83MrGAD3cEt6RxJ45LGN23a1OtwzMwmrTKTxQRwSNXjg9Nthb02\nIq6MiLGIGJs9O3NVQDMza1OZyWIlcLikeZL2As4Alud87U3AyZIOSDu2T063mZlZD5SWLCJiO3Au\nyZf8T4FrI2KdpIslvRxA0nMlbQReDXxS0rr0tQ8A7yVJOCuBi9NtZmbWA4qIXsdQiLGxsRgfH+91\nGGZmA0XSqogYy9pvoDu4zcysO5wszMwsk5OFmZllcrIwM7NMThZmZpbJycLMzDI5WZiZWSYnCzMz\ny+RkYWZmmZwszMws0/ReB2BmNpksWz3BZTet59ebt/K0WSMsnn8EC48d/OV4nCzMzAqybPUE51+/\nlq3bdgAwsXkr51+/FmDgE4aboczMCnLZTeufSBQVW7ft4LKb1vcoouI4WZiZFeTXm7e2tH2QOFmY\nmRXkabNGWto+SJwszMwKsnj+EYwMD+22bWR4iMXzj+hRRMVxB7eZWUEqndgeDWVmZk0tPHZ0UiSH\nWm6GMjOzTL6yMDPrY/0yyc/JwsysT/XTJD9FRFffsCxjY2MxPj7e6zDMzApz0tIVTNSZozEksTOC\n/UeGkWDzlm1tX3VIWhURY1n7+crCzKxPNZrMtyP9kb9567YntpV91eEObjOzPrRs9QTTpJZeU2Zp\nEScLM7M+U+mr2NFGN0FZpUUym6EkzQBeBcyt3j8iLi4lIjOzKa5eQcK8yiotkqfP4t+Bh4BVwGOl\nRGFmNgU1Ghbb7OpgZHioYSIps7RInmRxcEScUsq7m5lNMZUEMbF5KwIqDU3VHdRPmzVSdxTUaJpQ\nKgmmiNFQeeVJFj+QdFRErG314JJOAT4EDAGfioilNc/PAL4APAe4Hzg9Iu6VNAx8CjgujfELEXFJ\nq+9vZtZPaudN1PZIVDqoF88/Yrf9YNdVQ6/KieRJFs8H3ijpHpJmKAEREUc3e5GkIeAK4CXARmCl\npOURcWfVbmcDD0bE0yWdAVwKnA68GpgREUdJmgncKekrEXFvi5/PzKwn6jUx5emL+PXmrX1ZkDBP\nsji1zWMfD2yIiLsBJF0NLACqk8UC4ML0/nXARyVVrsz2kTQdGAEeB37fZhxmZl1Vb+b1edes2eNK\nop5KB3W/FSTMHDobEb8EZgEvS2+z0m1ZRoH7qh5vTLfV3ScitpN0pD+ZJHH8AfgN8CvgXyPigdo3\nkHSOpHFJ45s2bcoRkplZ+epdQeRJFP289kVmspD0duBLwB+lty9KemvJcR0P7ACeBswD/kHSobU7\nRcSVETEWEWOzZ88uOSQzs3xametQmXY3OmuES155VF9dTVTL0wx1NnBCRPwBQNKlwA+Bj2S8bgI4\npOrxwem2evtsTJuc9ifp6H4d8K2I2Ab8VtItwBhwd454zcx6qtFoplqjfdAXkVeeZCGSX/kVO9iV\nDJtZCRwuaR5JUjiDJAlUWw6cRZJ8FgErIiIk/Qp4EXCVpH2AE4EP5nhPM7Ouq+3MfuEzZvO1VRNN\nO7NHZ41wy5IXdTHKzuRJFp8FbpX09fTxQuDTWS+KiO2SzgVuIhk6+5mIWCfpYmA8Ipanx7lK0gbg\nAZKEAskoqs9KWkeSmD4bEbe38sHMzMqQlRgmNm/la6smeNVzRrn5rk17zKeA/u6baCRXiXJJx5EM\noQX4fkSsLjWqNrhEuZmVrXaUE7BHIqiovnLolwWM6um4RLmk/SLi95IOBO5Nb5XnDqw3OsnMbDJr\nZZRTdSd3vw2DbUezZqgvA39FUhOq+nxUEukeo5PMzCazVkY5lVXQr1caJouI+Kv033ndC8fMrBhF\nNv1UjtXoKqKIPol+bqqCfPMsvptnm5lZv6j0LUxs3kqwq0jfstW1o/dbO1Y9I8NDnHniHEZnjSDa\nmy9RZLxladZnsTcwEzhI0gHsGi67H3vOxDYz6xv1+hYqRfqyvsRrf+FveXx7wyGwRc2T6CTebmnW\nZ/G3wDtIZlGvYley+D3w0ZLjMjNrW6O+haw+h3o1nRoRFDZPot14u6lZn8WHgA9JemtEZM3WNjPr\nG41mUNd2OrdyFZF1rE7kjbeX8qzBvVPSrMoDSQdIenOJMZmZdWTx/CMYGR7abVul03nZ6glOWrqC\nuUtu5Lxr1uzWT/Dglm25jl/0pLpm8faLPMnibyJic+VBRDwI/E15IZmZdWbhsaNc8sqj9uh0Bnbr\nrM5TCbZWGQX/GsXbL/0VkGMGt6S1wNGR7pguanR7RDyzC/Hl5hncZpblpKUrchX4a0TAPUtPKy6g\nPtDxDO4q3wKukfTJ9PHfptvMzAZKpx3G/dSH0G15ksW7SBLE36WPv0OyPraZ2UDJWzociploN5nk\nWSlvZ0R8PCIWpbdPRkS+4QJmZn2kXkdyPUVMtJtsmk3KuzYiXpP2WezRsRERR5camZlZA+2Wxqjs\nU/vaetumcmKop2EHt6SnRsRvJP1xvedzrsPdNe7gNut/RdQ/alYmvNsrz/V7Pac88nZw51rPYhA4\nWZj1t3pf8iPDQy0372SNaBLwvMMO5N77t5b6JV7U5+m1ItazeJgmw5AjYr82YzOzSazRr+0i6jXl\n6ZwO4JZf7Fpup1KUDyj0S3wQ6jkVqVm5jycBSHov8BvgKpKkfSbw1K5EZ2YDpV5tpcoXdVH1mtpR\nxpf4INRzKlKeGdwvj4iPRcTDEfH7iPg4sKDswMxs8DT7td1ojkLW3IV6x2xH0V/i7X6eQZUnWfxB\n0pmShiRNk3Qm8IeyAzOz3qnUT5q35EZOWroi97oKzX5tt1v/qKgv+aK/xAehnlOR8kzKex3wofQW\nwC3pNjObhJo1JWU14zSrntps2OpJS1c07IzOmkg3MjyNR7ftbFrnqYwv8UafZzL2V4BHQ5lZjUaj\njUZnjWSu39DqCKE8+zfrs6jsC7t/ab/wGbO5+a5NU+JLvFOF1YaS9CfAx4GnRMSzJB1N0o/xvgLi\nNLM+00nHbau/ti+6YV3dPo5/uPa2J45XfcyJzVsZktgRscecCieDcuWpOvtfwGLgkxFxbLrtjoh4\nVhfiy81XFmbF6OTKIq9lqye4cPk6Nm9tvH7E8DSx797T2bxlm68OSlRk1dmZEfFjSdXbtrcdmZn1\ntcXzj6jbNNROm3+9ORdArqGw23bGE4sRlTVXwvLLkyx+J+kw0gl6khaRzLsws0moqI7bRh3lew9P\na2so7GSe8DYI8iSLtwBXAs+QNAHcQzIxz8wmqeq+gnY1mnPRyZyJyTrhbRA0TRaSpgFjEfGXkvYB\npkXEw3kPLukUkiG3Q8CnImJpzfMzgC8AzwHuB06PiHvT544GPgnsB+wEnhsRj+Z9bzPrrTK+2DuZ\nKzEZiv71UtNJeRGxE/jH9P4fWkwUQ8AVwKnAkcBrJR1Zs9vZwIMR8XTgcuDS9LXTgS8Cb0qXb/0L\nIN9K6mbWF1r9Yp85PI0DZg4jYNbIMMNDu/WTdjRXotIkNrF5K8GuJrG8kw0tXzPUf0h6J3ANVTO3\nI+KBxi8B4HhgQ0TcDSDpapIyIXdW7bMAuDC9fx3wUSU96SeTrPN9W/pe9+eI08z6SL2O8mpDEjsj\nGv7KL/JKYKoV/StDnmRxevrvW6q2BXBoxutGgfuqHm8ETmi0T0Rsl/QQ8GTgT4CQdBMwG7g6It6f\nI1azKalfm1hmTG/cmb0zgnuWntbwtUX0m1RMtaJ/ZchMFhExrxuB1JgOPB94LrAF+G46Fvi71TtJ\nOgc4B2DOnDldD9KsH3RSnqOo929neGw3C+41K0Ni+WQWEpS0t6S/l3S9pK9JeoekvXMcewI4pOrx\nwem2uvuk/RT7k3R0bwS+FxG/i4gtwDeA42rfICKujIixiBibPXt2jpDMJp9mTSxla9QXUG9mdrWs\n/od2Cxk2MtWK/pUhTzPUF4CHgY+kj19HsrbFqzNetxI4XNI8kqRwBnsWIFwOnAX8EFgErIiISvPT\nP0qaCTwO/DlJB7iZ1Si7iaV2tvXM4WnMGB56YsJcrazhsVlLn5ZxpTTViv6VIU+yeFZEVI9iulnS\nnQ33TqV9EOcCN5EMnf1MRKyTdDEwHhHLgU8DV0naADxAklCIiAclfYAk4QTwjYi4saVPZjZFlNnE\nsmz1BIu/ehvbdu4qC7Rl2062bNvZ1vHylAwpqzO6yD6QqShPsviJpBMj4kcAkk4AchVhiohvkDQh\nVW97T9X9R2lwhRIRXyQZPmtmTRRZnqPWZTet3y1RdCJvTO6M7k95ksVzgB9I+lX6eA6wXtJaICLi\n6NKiM7NMZTaxFPEFLWgpJndG96c8yeKU0qMws4500sTSbNht1sJDWdqpVFvmlZK1L8/Q2V92IxAz\n6756ncmLv3obF92wjs1btrH/yDDTBO20RLX7Be/O6P6U58rCzCapep3J1aXBN2/dxvA0sfd05erU\nFsmIlKwRT1ncGd1/nCzMOtCvM6fzWLZ6IlcT07adwR/ttzd3LnnRHp/Xy5dOHVlVZ4eA/4iIF3Yp\nHrOBUdR8gF4knHcvW8uXfvSr7B1TlY5u/+Kfupomi4jYIWmnpP0j4qFuBWU2CIqYD9DtUh15ljOt\nxyORLE8z1CPAWknfYfeqs28rLSqzAVDEfIBuVkOtXE202lftkUgG+ZLF9enNzKoUMR+gG6U6Lrtp\nfdvDXw+YOcwFL3umm54s19DZz0vai6RsOMD6iPBCRDblFTEfoOgJaNX9H8la1+2V5XCSsFqZyULS\nXwCfB+4lGRl3iKSzIuJ75YZm1t+KmA9Q5AS02v6PVhKFgDNPnMP7Fh7V8vva1JCnGerfgJMjYj2A\npD8BvkJSBsRsSut0dFAnCad2FNWWx7c3rfbaiK8iLI88yWK4kigAIuJnkoZLjMlsSmkn4dQbRdUq\nX01YK/Iki3FJn2JXBdgzyVl11szKUW8UVSs6nWFtU0+eZPF3JOtvV4bKfh/4WGkRmVmmdkdLvd5X\nEtamhslC0ncj4sXAxRHxLuAD3QvLrHv6sWRHo3Wt25lQV+FEYZ1odmXxVEnPA14u6WqSJs4nRMRP\nSo3MrAu6PYM6b0zVq9NNbN7KO65Z0/bx2u3A7sckar3TLFm8B/hn4GD2vKoIoLUi9WZ9qJszqPO6\ncPm6jlena2cdiWr9mESttxomi4i4DrhO0j9HxHu7GJNZ1/TjEp7tNjNVDA+p4/Ic/ZhErbfyzOB2\norBJq1+W8Oy0LEdFUXMm+jGJWm95PQub0nqxhGdtX8DcJ4/wg1880HKBv4ppgg+85phCf/H3SxK1\n/jGt1wGY9dLCY0e55JVHMTprBJG09V/yyqNKa2p597K1nHfNGiY2byVI+gJu6SBRQLLk6fnXr2XZ\n6omiwmTx/CMYGR7abZurz05tua4s0kWQnlK9f0TkXznFrI91a0GfZasn+GILCw61ouj+BK+DbbXy\nFBJ8K3AB8D9ApTJZAEeXGJfZpHPRDes6en2lP+K8a9bUvRIpuj/Bq+JZtTxXFm8HjoiI+8sOxmwQ\nNZuP0O7KdBX1ynI06ghv1p/gORPWqTzJ4j7AS6rapFHkF2e9+QiLv3obF92wjge3tD8Ettls61Y7\n5T1nwoqQJ1ncDfynpBuBxyobI8LlP2zgFP3FWW8+wrad0VGimDUy3LQsR6v9CZ4zYUXIkyx+ld72\nSm9mA6voL86i+wlGhoe48OXPzNyvlf4Ez5mwIuSZlHcRgKSZEbGllYNLOgX4EDAEfCoiltY8PwP4\nAslCSvcDp0fEvVXPzwHuBC6MiH9t5b3N6inyi3PZ6gmmSeyI9ge+vv7EOdx816ZS+xI8Z8KKkDnP\nQtKfSboTuCt9/GxJmSXK0+G2VwCnAkcCr5V0ZM1uZwMPRsTTgcuBS2ue/wDwzcxPYZZToy/IVr84\nK81ZnSSK0VkjvG/hUdyy5EXcs/Q0Fs8/gstuWs+8JTdy0tIVhc2b8JwJK0KeSXkfBOaT/PInIm4D\nXpDjdccDGyLi7oh4HLgaWFCzzwKS9b0BrgNeLEkAkhYC9wCdjTc0q1LUF2eniw/Vvmcl+VRP1itq\nol23Jx7a5JRrUl5E3Jd+h1fk+SsZJRlJVbEROKHRPhGxXdJDwJMlPQq8C3gJ8M48MZrl0ema150M\ng50xfRqPb99Z9z3L7oT2nAnrVK6hs+m6FpGuvf124KflhsWFwOUR8UhNktqNpHOAcwDmzJlTckg2\nWbS75nX1GhOtGJJ47QmHNB3h5E5o63d5ksWbSDqpR4EJ4Nsky6xmmQAOqXp8cLqt3j4bJU0H9idp\n7joBWCTp/cAsYKekRyPio9UvjogrgSsBxsbGOlsAwKyJi25ofY2J4SFx2aJn50pM7oS2fpcnWeyM\niDOrN0iaR9qH0cRK4PB03wngDOB1NfssB84CfggsAlZERAD/q+q9LgQeqU0UNnkUPbu4iON12uRU\nr1R4s7h6Uf3WrBV5ksUNkk6NiN8DSPpT4KvAs5q9KO2DOBe4iWTo7GciYp2ki4HxiFgOfBq4StIG\n4AGShGJTSNGT5No9XhFlOZqtTJcVlwv3Wb9TZAz9k3Qa8I/AacARJPMizoyI9hcFLsHY2FiMj4/3\nOgxr0UlLV9Rtfml3WdB2jvfuZWs7rgb7wdObrydR9Oc0K4qkVRExlrVfnkl5N6Yd298GngS8IiJ+\nVkCMZh117NZr1mn1eEUkipMOOzDzCsAd2DboGiYLSR+B3Soh7w/8AjhXEhHxtrKDs8mv3Y7dRs06\ns2YO163LVDlep81N1aYJXnfC7gX/GvVLuAPbBl2zK4vaNp1VZQZiU1M7HbvLVk9w3rVrqG1B3bpt\nBzOmT2NkeKju8ToZ/lptSOLfXrPnKKdm/RLuwLZB1zBZRMTnGz1nVpRWOnaTL+Pb2bpt5x7PVTy0\ndRuXn37MHscD6iaYVo0MD3HJK5MriZOWrtjtPZpNrKv0S7gD2wZVng7uw4FLSOo77V3ZHhGHlhta\na9zBPbnl7VuYNTLMmgtO3q05aO/haU0TTCsOmDnMaUc/la+tmtjjKqFR+Q8B9yw9rZD3NytaYR3c\nwGdJllW9HHgh8Nfkqyll1rE8VxPVNm/dxtwlN+62rd1EMTprhBc+Y/ZuieHBLdv40o9+tceyplu3\n7WCoQQVa90vYZJAnWYxExHclKSJ+CVwoaRXwnpJjsymmcjUwsXkrgrrrTHfLaJOmpUZx7Yho2F9i\nNujyXCE8Jmka8HNJ50p6BbBvyXHZFFNddRV6myhgV+d0vRFMjVSqubq6q01Gea4s3g7MBN4GvJek\nKeoNZQZlU0+nJb87NU1QO0iqWdNS7ZVP5QrC1V1tssqTLOZGxErgEZL+CiS9Gri1zMBscqvugN5/\nZLiQeQ/teP2JyTyJeTX9HBWNmpZe9ZzR0le4M+sneZLF+SS1oLK2meVSOx+hnUSxz15D/MsrkiGs\nnYx6uvmuTUDjyYHVfRdODDaVNZvBfSrwUmBU0oerntoP2F52YDZ5ddLkVK+aa/X9dy9bW3e0UiOV\nchvNJs25acms+ZXFr0lmcb+c3WdvPwycV2ZQNrm1Uw+p0doQ9cprvG/hUXts3/L49qZlQFz11ay5\nPJPyhiOiNw3KLfCkvP5UPRy2UWdxI5X9Rxt8cdc2Z8GuGdad7Gs2lRRZdbbvE4X1p9ov6LyJIu+X\neCvrVvvKwawzeTq4zVq2bPUE/3DtbS1dSUByNZH3136j5qxGcyPc92DWvtxlOyTNLDMQmzwqVxSt\nJoqR4aG61VwbaVRGQ2kMZlaczGQh6XmS7gTuSh8/W9LHSo/MBlY7o53ame28eP4RqM72SGMws+Lk\nubK4HJgP3A8QEbcBLygzKBtsrYx2Ghke4oOnH8MtS17UchPRwmNHGw6Rndi81VcXZgXK1QwVEffV\nbOpdXQbre1lVVoeUXA8UUTtptMl7nX/9WicMs4Lk6eC+T9LzgEjX4n478NNyw7JB1miCWxnDVBfP\nP6Lh6neNRkaZWevyXFm8CXgLMApMAMekj83qWnjsaNeqry48dpR99278m6edCYBmtqc88yx+B5zZ\nhVhsEunmMNXNdWZmV3jhIbNiZCYLSfOAtwJzq/ePiJeXF5b1u3ozs7NmXJdl5l5D/OHx+t1oXnjI\nrBh5+iyWAZ8GbgCKWcjYBtay1RNcuHzdbpViK/MpKv9ObN7Kedes4R3XrCk9cSxbPdEwUYwMT3N/\nhVlB8iSLRyPiw9m72WRXr75SI5Xu5sqKc0ApX9zN5lM82uba22a2pzwd3B+SdIGkP5N0XOVWemTW\nd9otLV4ZlVSGZh3Y7q8wK06eK4ujgP8NvIhdzVCRPrZJrrpvohNljUpqtGiRcH+FWZHyXFm8Gjg0\nIv48Il6Y3nIlCkmnSFovaYOkJXWenyHpmvT5WyXNTbe/RNIqSWvTf52YeqDS7NRpooDyfuUvnn8E\nI8NDu20TcOaJc9xfYVagPFcWdwCzgN+2cmBJQ8AVwEuAjcBKScsj4s6q3c4GHoyIp0s6A7gUOB34\nHfCyiPi1pGcBN5HM87AuaaVq7DTBzti1/oRgtzIclRXnyuDS42bdkSdZzALukrQSeKyyMcfQ2eOB\nDRFxN4Ckq4EFQHWyWABcmN6/DvioJEXE6qp91gEjkmZExGNY4apXldt/ZJjHt+9gS87O4Q+efkyu\n1evK/PJ26XGz8uVJFhe0eexRoLqm1EbghEb7RMR2SQ8BTya5sqh4FfCTeolC0jnAOQBz5sxpM8yp\nrXbN6uohsVlGZ43U/ZL2l7fZ5JNnBvd/dSOQeiQ9k6Rp6uR6z0fElcCVkCyr2sXQJoVlqyd2SxSt\nKLNpycz6T8NkIem/I+L5kh5m9yZoARER+2UcewI4pOrxwem2evtslDQd2J+0FLqkg4GvA2+IiF/k\n+TDWXCfrYVfr9gxtM+u9ZlcW+wBExJPaPPZK4PC0XMgEcAbwupp9lgNnAT8EFgErIiIkzQJuBJZE\nxC1tvr9VaXc97Iqyqsaa2WBoliw6atZJ+yDOJRnJNAR8JiLWSboYGI+I5SRlRK6StAF4gCShAJwL\nPB14j6T3pNtOjoiWRmTl0e3O2F656IZ1bU2oAzhg5jAXvOyZk/K8mFk+iga/MCVtBD7Q6IUR0fC5\nXhgbG4vx8fGWXlOvfMWg/4Ku19RUO5Q1yz57DbHl8R2TOnmaWULSqogYy9qv2ZXFELAv1F3meFKo\nV75ikBfMadTUlDdRuC/CzBpplix+ExEXdy2SHmhUgmIQF8xpZRJdrUG/mjKz8jVLFpP2iqKiUV2h\nQSpAV69keCt8NWFmeTRLFi/uWhQ90mit6EGYP9BpkvDVhJm1omGyiIgHuhlILwxiXaFOkwR4dJOZ\ntS5PuY9Jrd9LU1QP7d17eBpb21jQp1fLnZrZ5DHlk0U/yRr22kqicDOTmRXJyaJPdDrstZqbmcys\naE4WfaLdJUurOUmYWVmcLPpEJ3M7nCTMrGxOFj1Qrx5VozkfzVSWD33fwqPKCdTMLJVnDW4rUPW6\n1gFMbN7K+dev5YXPmL3HWtIVldmRs0aGOWDmMCKZTHf56cc4UZhZV/jKossa1aO6+a5NXPLKo/YY\nDeXhrmbWD5wsuqxZPap+n/NhZlOXm6G6rFHdqUGqR2VmU4+TRZctnn/EHn0Tg1KPysymLjdDddkg\n1qMyM3Oy6AH3TZjZoHEzlJmZZXKyMDOzTE4WZmaWycnCzMwyOVmYmVkmJwszM8vkZGFmZpmcLMzM\nLJOThZmZZXKyMDOzTKUmC0mnSFovaYOkJXWenyHpmvT5WyXNrXru/HT7eknzy4zTzMyaKy1ZSBoC\nrgBOBY4EXivpyJrdzgYejIinA5cDl6avPRI4A3gmcArwsfR4ZmbWA2VeWRwPbIiIuyPiceBqYEHN\nPguAz6f3rwNeLEnp9qsj4rGIuAfYkB7PzMx6oMxkMQrcV/V4Y7qt7j4RsR14CHhyztci6RxJ45LG\nN23aVGDoZmZWbaA7uCPiyogYi4ix2bNn9zocM7NJq8xkMQEcUvX44HRb3X0kTQf2B+7P+VozM+uS\nMpPFSuBwSfMk7UXSYb28Zp/lwFnp/UXAioiIdPsZ6WipecDhwI9LjNXMzJoobaW8iNgu6VzgJmAI\n+ExErJN0MTAeEcuBTwNXSdoAPECSUEj3uxa4E9gOvCUidpQVq5mZNafkh/zgGxsbi/Hx8V6HYWY2\nUCStioixrP0GuoPbzMy6w8nCzMwyOVmYmVkmJwszM8vkZGFmZpmcLMzMLJOThZmZZXKyMDOzTE4W\nZmaWycnCzMwyOVmYmVmmSVMbStIm4Jc5dz8I+F2J4RRlUOKEwYnVcRbLcRarF3H+cURkLgg0aZJF\nKySN5ymc1WuDEicMTqyOs1iOs1j9HKeboczMLJOThZmZZZqqyeLKXgeQ06DECYMTq+MsluMsVt/G\nOSX7LMzMrDVT9crCzMxaMOUwJro2AAAIUUlEQVSShaRTJK2XtEHSkl7HU03SvZLWSlojaTzddqCk\n70j6efrvAT2I6zOSfivpjqptdeNS4sPp+b1d0nE9jvNCSRPpOV0j6aVVz52fxrle0vwuxnmIpJsl\n3SlpnaS3p9v76pw2ibMfz+nekn4s6bY01ovS7fMk3ZrGdI2kvdLtM9LHG9Ln5/Y4zs9JuqfqnB6T\nbu/Z39MeImLK3IAh4BfAocBewG3Akb2Oqyq+e4GDara9H1iS3l8CXNqDuF4AHAfckRUX8FLgm4CA\nE4FbexznhcA76+x7ZPrffwYwL/3/YqhLcT4VOC69/yTgZ2k8fXVOm8TZj+dUwL7p/WHg1vRcXQuc\nkW7/BPB36f03A59I758BXNPjOD8HLKqzf8/+nmpvU+3K4nhgQ0TcHRGPA1cDC3ocU5YFwOfT+58H\nFnY7gIj4HvBAzeZGcS0AvhCJHwGzJD21h3E2sgC4OiIei4h7gA0k/3+ULiJ+ExE/Se8/DPwUGKXP\nzmmTOBvp5TmNiHgkfTic3gJ4EXBdur32nFbO9XXAiyWph3E20rO/p1pTLVmMAvdVPd5I8//5uy2A\nb0taJemcdNtTIuI36f3/BzylN6HtoVFc/XiOz00v4T9T1YzXF3GmzR/HkvzC7NtzWhMn9OE5lTQk\naQ3wW+A7JFc2myNie514nog1ff4h4Mm9iDMiKuf0X9JzermkGbVxpnr29zTVkkW/e35EHAecCrxF\n0guqn4zkurTvhq/1a1ypjwOHAccAvwH+rbfh7CJpX+BrwDsi4vfVz/XTOa0TZ1+e04jYERHHAAeT\nXNE8o8ch1VUbp6RnAeeTxPtc4EDgXT0Msa6pliwmgEOqHh+cbusLETGR/vtb4Osk/8P/T+WyM/33\nt72LcDeN4uqrcxwR/5P+ce4E/g+7mkV6GqekYZIv4C9FxPXp5r47p/Xi7NdzWhERm4GbgT8jabaZ\nXieeJ2JNn98fuL9HcZ6SNvlFRDwGfJY+O6cw9ZLFSuDwdITEXiQdW8t7HBMAkvaR9KTKfeBk4A6S\n+M5KdzsL+PfeRLiHRnEtB96QjuI4EXioqmml62rad19Bck4hifOMdFTMPOBw4MddiknAp4GfRsQH\nqp7qq3PaKM4+PaezJc1K748ALyHpY7kZWJTuVntOK+d6EbAivZrrRZx3Vf1IEEm/SvU57Y+/p171\nrPfqRjK64Gck7Zn/1Ot4quI6lGQkyW3AukpsJO2o3wV+DvwHcGAPYvsKSXPDNpI207MbxUUyauOK\n9PyuBcZ6HOdVaRy3k/zhPbVq/39K41wPnNrFOJ9P0sR0O7Amvb20385pkzj78ZweDaxOY7oDeE+6\n/VCShLUB+CowI92+d/p4Q/r8oT2Oc0V6Tu8AvsiuEVM9+3uqvXkGt5mZZZpqzVBmZtYGJwszM8vk\nZGFmZpmcLMzMLJOThZmZZXKysL4j6ZHsvTo6/hslPa3q8b2SDir4Pd4m6aeSvlTkcauOv1DSkWUc\n26weJwubit4IPC1rpw69GXhJRJxZ0vEXklR5NesKJwsbCOnM169JWpneTkq3X5gWs/tPSXdLelvV\na/5ZyboK/y3pK5LeKWkRMAZ8KV03YCTd/a2SfqJkPZFnpK//86r1BVZXZtjXxPX3ku5Ib+9It32C\nZDLYNyWdV7P/M5WsZ7AmLRp3eLr99VXbPylpKN3+iKR/UbL+wY8kPUXS84CXA5el+x+W3r6lpAjl\n96s+w+eUrIfwg/T8LKqK5V3p571N0tJ0W6PjvDr9jLdJ+l4B/0lt0PRqNqBvvjW6AY/U2fZlkkKL\nAHNISlBAsrbCD0jWUDiIpL7PMElBtjUkM3WfRDIr+p3pa/6TqpmwJOuIvDW9/2bgU+n9G4CT0vv7\nAtNrYnoOyazafdLn1wHHVh3zoDqf4yPAmen9vYAR4E/T9xpOt38MeEN6P4CXpfffD7w7vf85qtY/\nIJn5fXh6/wSS8hWV/b5K8sPwSJIS/ZAUq/wBMDN9fGDGcdYCo+n9Wb3+f8S37t8qBbbM+t1fAkdq\n15ID+ymphgpwYyQF2B6T9FuS0t4nAf8eEY8Cj0q6IeP4lWJ+q4BXpvdvAT6Q9jtcHxEba17zfODr\nEfEHAEnXA/+LpJxDIz8E/knSwekxfy7pxSSJZ2X6+UbYVUTwceD/VsX2ktoDpufhecBXq87PjKpd\nlkVS9O9OSZWy538JfDYitgBExAMZx7kF+Jyka9l1rmwKcbKwQTENODH98n9C+qX2WNWmHbT3/3Xl\nGE+8PiKWSrqRpB7SLZLmR8RdbRz7CRHxZUm3AqcB35D0tyT1fz4fEefXecm2iKjU5Gn02aaRrNtw\nTIO3rT4/zRb4aXiciHiTpBPSuFdJek5EdLVKq/WW+yxsUHwbeGvlgdI1ipu4BXiZkjWP9wX+quq5\nh0mappqSdFhErI2IS0kqFteuj/B9YKGkmUoqBb8i3dbsmIcCd0fEh0kqoB5N0vSzSNIfpfscKOmP\nM8J74jNEssbEPZJenb5ekp6d8frvAH8taWblPZsdJz0Xt0bEe4BN7F4226YAJwvrRzMlbay6/T3w\nNmAs7RS+E3hTswNExEqSiqi3k6xhvJZkNTRI2vE/UdPBXc870k7d20kq2X6z5j1+kh7rxyQryH0q\nIpo1QQG8BrhDyUppzyJZMvNO4N0kqyTeTvJFnrV05tXA4rTj/TDgTOBsSZWqxU2XC46Ib5Gcn/E0\nlnemTzU6zmVpZ/gdJH0dt2XEZ5OMq87apCVp34h4JP31/D3gnPQL3sxa5D4Lm8yuVDJxbW+SPgEn\nCrM2+crCzMwyuc/CzMwyOVmYmVkmJwszM8vkZGFmZpmcLMzMLJOThZmZZfr/jJ72nYHasa4AAAAA\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b4DUH5SGyNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_sentiment(simple_model, \"This film is terrible what can I say\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKDAunDL_IYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "pickle_out = open(\"training_epochs_2.pickle\",\"wb\")\n",
        "pickle.dump((simple_model.training_accuracies, simple_model.validation_accuracies), pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiERmDzt_rcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}